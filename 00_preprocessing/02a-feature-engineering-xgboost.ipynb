{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create features for Xgboost model\n",
    "#### The script takes data from the 1-preprocessed folder and returns a classic dataframe in './data/2-features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "pd.options.display.max_columns = 300\n",
    "\n",
    "data_cols = ['Accuracy','Bearing',\n",
    "             'acceleration_x','acceleration_y','acceleration_z',\n",
    "             'gyro_x','gyro_y','gyro_z',\n",
    "             'Speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(_filename):\n",
    "    print(\"Processing %s\" %_filename)\n",
    "    df = pd.read_parquet('../data/1-preprocessed/'+_filename)\n",
    "    dt = pd.read_csv('../data/0-raw_data/safety/labels/part-00000-e9445087-aa0a-433b-a7f6-7f4c19d78ad6-c000.csv')\n",
    "    dt = dt.groupby('bookingID', as_index=False)['label'].max()\n",
    "    \n",
    "    #add labels\n",
    "    df = df.merge(dt, on='bookingID', how='left')\n",
    "    #we reset second to start from 0 for every (bookingID, bookingID2)\n",
    "    df = df.sort_values(by=['bookingID','second']).reset_index(drop=True)\n",
    "    df['second'] = df.groupby(['bookingID'])['second'].cumcount()\n",
    "    \n",
    "    #manual feature creation\n",
    "    #every acceleration >= 9.8m/s2 is considered as harsh\n",
    "    for col in ['acceleration_x','acceleration_y','acceleration_z']:\n",
    "        df['harsh_'+col] = (np.abs(df[col])>= 9.8).astype(int)\n",
    "        \n",
    "    # calculate the slope for gyro and speed\n",
    "    for col in ['gyro_x','gyro_y','gyro_z','Speed']:\n",
    "        for i in range(1,6):\n",
    "            df['d_'+col+\"-\"+str(i)] = df.groupby(['bookingID','bookingID2'])[col].shift(+i)\n",
    "            df['d_'+col+\"-\"+str(i)] = (df['d_'+col+\"-\"+str(i)] - df[col])/i\n",
    "    \n",
    "    # for the slopes, flag when they are above the 80 percentile\n",
    "    for d_col in [col for col in df.columns if col.startswith('d_') ]:\n",
    "        df['harsh_positive_'+d_col] = ((df[d_col]>=df.loc[df[d_col]>0,col].quantile(.8)) & (df[col]>0)).astype(int)\n",
    "        df['harsh_negative_'+d_col] = ((df[col]<=df.loc[df[col]<0,col].quantile(.2)) & (df[col]<0)).astype(int)\n",
    "        \n",
    "    df2 = df.copy()\n",
    "    df2 = df2.drop(['bookingID2','second','label'], axis=1)\n",
    "    df2 = df2.groupby(['bookingID']).agg(['count', 'mean', 'std', 'sum', 'min', 'median', 'max'])\n",
    "    df2.columns = ['_'.join(col).strip() for col in df2.columns.values]\n",
    "    \n",
    "    for col in data_cols:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    \n",
    "    df2 = df2.reset_index()\n",
    "\n",
    "    #add labels\n",
    "    df2 = df2.merge(dt, on='bookingID', how='left')\n",
    "    #save file to parquet\n",
    "    df2.to_parquet('../data/2-features/'+_filename.replace('.parquet','')+'_xgboost.parquet')\n",
    "    print(\"Finished with %s \" %_filename)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing features.parquet\n",
      "Finished with features.parquet \n",
      "Finished to create features for XGBoost.\n"
     ]
    }
   ],
   "source": [
    "mypath = '../data/1-preprocessed/'\n",
    "onlyfiles = ['features.parquet']\n",
    "\n",
    "for filename in onlyfiles:\n",
    "    create_matrix(filename)\n",
    "print(\"Finished to create features for XGBoost.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
